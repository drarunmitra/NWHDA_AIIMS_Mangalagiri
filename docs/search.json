[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NWHDA - AIIMS Mangalagiri",
    "section": "",
    "text": "Preface\nWelcome to the “Introduction to Health Data Science Using R” workshop! Get ready to embark on a transformative journey into the dynamic world of health data science. This companion workbook is your roadmap and toolkit for our action-packed, three-day adventure. We’re here to build a rock-solid foundation in data science specifically for healthcare professionals, all while harnessing the full power of the R programming language and the RStudio interface.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#workshop-goals",
    "href": "index.html#workshop-goals",
    "title": "NWHDA - AIIMS Mangalagiri",
    "section": "Workshop Goals",
    "text": "Workshop Goals\n\nPrimary Objective\nOur mission is simple yet ambitious: to empower you with the essential tools and knowledge to master health data science using R. You’ll dive deep into the R programming language, navigate the versatile RStudio environment, and leverage the tidyverse workflow for cutting-edge data analysis. By the end, you’ll be a healthcare professional who is equiped with the concepts and information needed to make your path in the exciting world of Health Data Science.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#key-topics",
    "href": "index.html#key-topics",
    "title": "NWHDA - AIIMS Mangalagiri",
    "section": "Key Topics",
    "text": "Key Topics\n\nData Wrangling:\nLearn to clean, reshape, and prepare your datasets like a pro, tackling common challenges using the power of data manipulation and transformation.\n\n\nData Visualization:\nLearn to create informative and aesthetically pleasing charts using the versatile ggplot2 package. Turn data into compelling stories with stunning visualizations using various ggplot extensions.\n\n\nReproducible Research:\nLearn to document your processes meticulously, ensuring your analyses are transparent, replicable, and credible. Kick-start you research journey with reproducible workflows.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#expected-outcomes",
    "href": "index.html#expected-outcomes",
    "title": "NWHDA - AIIMS Mangalagiri",
    "section": "Expected Outcomes",
    "text": "Expected Outcomes\nBy the end of this workshop, you’ll be able to:\n\nData Wrangling\n\nImport data from various sources into R.\nClean and pre-process data for further analysis.\nTransform data to explore insights and interpretations.\n\n\n\nData Visualization\n\nCreate a variety of data visualizations (plots and charts).\nCustomize visualizations to highlight key trends and communicate them effectively.\nApply the best practices of data visualization to make them impactful.\n\n\n\nReproducible Research\n\nClear and well-documented reserach workflows.\nEfficiently organized using data-science projects\n\nThis workshop isn’t just about learning - it’s about transforming the way you interact with data. Whether you’re a beginner eager to dive into the world of programming or a seasoned professional looking to sharpen your skills, this workshop is designed to provide practical knowledge and hands-on experience that will set you apart.\nWe’re thrilled to have you join us and can’t wait to see the incredible things you’ll achieve with your new found skills in health data science using R. Let’s dive in and start this exciting journey together!\nLet’s Get Started!!!\n\n\nDISCLAIMER - What is not covered in the workshop?\nThis is not a workshop on Epidemiology or Biostatistics. Though we will be touching on many epidemiological and statistical aspects, we will deliberately skip going into the deeper concepts. Future workshops covering these concepts more in detail may be thought of if there are additional requests and a threshold number of participants.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapter_1_primer.html#introduction-to-r-and-rstudio",
    "href": "chapter_1_primer.html#introduction-to-r-and-rstudio",
    "title": "1  Basic Concepts",
    "section": "1.1 Introduction to R and RStudio",
    "text": "1.1 Introduction to R and RStudio\n\n\n\n\n1.1.1 What is R?\n\nOpen source (free!) statistical programming language/software\nIt can be used for:\n\nWorking with data - cleaning, wrangling and transforming\nConducting analyses including advanced statistical methods\nCreating high-quality tables & figures\nCommunicate research with R Markdown\n\nIt is constantly growing!\nHas a strong online support community\nSince it’s one programming language, it is versatile enough to take you from raw data to publishable research using free, reproducible code!\n\n\n\n\n\n\n1.1.2 What is RStudio?\n\n\nRStudio is a free, open source IDE (integrated development environment) for R. (You must install R before you can install RStudio.)\nIts interface is organized so that the user can clearly view graphs, tables, R code, and output all at the same time.\nIt also offers an Import-Wizard-like feature that allows users to import CSV, Excel, SPSS (*.sav), and Stata (*.dta) files into R without having to write the code to do so.\n\n\n\n\n1.1.3 R versus Others Softwares\nExcel and SPSS are convenient for data entry, and for quickly manipulating rows and columns prior to statistical analysis. However, they are a poor choice for statistical analysis beyond the simplest descriptive statistics, or for more than a very few columns.\n\n\n\nProportion of articles in health decision sciences using the identified software\n\n\n\n\n1.1.4 Why should you learn R\n\nR is becoming the “lingua franca” of data science\nMost widely used and it is rising in popularity\nR is also the tool of choice for data scientists at Microsoft, Google, Facebook, Amazon\nR’s popularity in academia is important because that creates a pool of talent that feeds industry.\nLearning the “skills of data science” is easiest in R\n\n\n\n\n\nIncreasing use of R in scientific research\n\n\n\nSome of the reasons for chosing R over others are are:\n\nMissing values are handled inconsistently, and sometimes incorrectly.\nData organisation difficult.\nAnalyses can only be done on one column at a time.\nOutput is poorly organised.\nNo record of how an analysis was accomplished.\nSome advanced analyses are impossible",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basic Concepts</span>"
    ]
  },
  {
    "objectID": "chapter_1_primer.html#health-data-science",
    "href": "chapter_1_primer.html#health-data-science",
    "title": "1  Basic Concepts",
    "section": "1.2 Health Data Science",
    "text": "1.2 Health Data Science\nHealth Data Science is an emerging discipline, combining mathematics, statistics, epidemiology and informatics.\nR is widely used in the field of health data science and especially in healthcare industry domains like genetics, drug discovery, bioinformatics, vaccine reasearch, deep learning, epidemiology, public health, vaccine research, etc.\n\n\n\n\nApplications of Data Science in Healthcare\n\n\nAs data-generating technologies have proliferated throughout society and industry, leading hospitals are trying to ensure this data is harnessed to achieve the best outcomes for patients. These Internet of things (IoT) technologies include everything from sensors that monitor patient health and the condition of machines to wearables and patients’ mobile phones. All these comprise the “Big Data” in healthcare.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basic Concepts</span>"
    ]
  },
  {
    "objectID": "chapter_1_primer.html#reproducible-research",
    "href": "chapter_1_primer.html#reproducible-research",
    "title": "1  Basic Concepts",
    "section": "1.3 Reproducible Research",
    "text": "1.3 Reproducible Research\nResearch is considered to be reproducible when the exact results can be reproduced if given access to the original data, software, or code.\n\nThe same results should be obtained under the same conditions\nIt should be possible to recreate the same conditions\n\n\nReproducibility refers to the ability of a researcher to duplicate the results of a prior study using the same materials as were used by the original investigator. That is, a second researcher might use the same raw data to build the same analysis files and implement the same statistical analysis in an attempt to yield the same results. Reproducibility is a minimum necessary condition for a finding to be believable and informative.\n\n— U.S. National Science Foundation (NSF) subcommittee on Replicability in Science\nThere are four key elements of reproducible research:\n\ndata documentation\ndata publication\ncode publication\noutput publication\n\n\n\n\n\n\nBaker, M. 1,500 scientists lift the lid on reproducibility. Nature 533, 452–454 (2016)\n\n\n\n\n\n\n\n\nFlavours of Reproducible Research\n\n\n\nFactors behind irreproducible research\n\nNot enough documentation on how experiment is conducted and data is generated\nData used to generate original results unavailable\nSoftware used to generate original results unavailable\nDifficult to recreate software environment (libraries, versions) used to generate original results\nDifficult to rerun the computational steps\n\n\n\n\n\nThreats to Reproducibility (Munafo. et. al, 2017)\n\n\nWhile reproducibility is the minimum requirement and can be solved with “good enough” computational practices, replicability/ robustness/ generalisability of scientific findings are an even greater concern involving research misconduct, questionable research practices (p-hacking, HARKing, cherry-picking), sloppy methods, and other conscious and unconscious biases.\nWhat are the good practices of reproducible research?\nHow to make your work reproducible?\nReproducible workflows give you credibility!\n\n\n\nCartoon created by Sidney Harris (The New Yorker)\n\n\n\n\n\nReproducibility spectrum for published research. Source: Peng, RD Reproducible Research in Computational Science Science (2011)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basic Concepts</span>"
    ]
  },
  {
    "objectID": "chapter_2_rstudio.html#install-r",
    "href": "chapter_2_rstudio.html#install-r",
    "title": "2  Getting Comfortable with R and RStudio",
    "section": "2.1 Install R",
    "text": "2.1 Install R\n\nGo here: https://cran.rstudio.com/\nChoose the correct “Download R for. . .” option from the top (probably Windows or macOS), then…\n\n\n\nFor Windows users, choose “Install R for the first time” (next to the base subdirectory) and then “Download R 4.4.0 for Windows”\nFor macOS users, select the appropriate version for your operating system (e.g. the latest release is version 4.4.0, will look something like R-4.4.0-arm64.pkg), then choose to Save or Open\nOnce downloaded, save, open once downloaded, agree to license, and install like you would any other software.\n\n\n\n\nIf it installs, you should be able to find the R icon in your applications.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Comfortable with R and RStudio</span>"
    ]
  },
  {
    "objectID": "chapter_2_rstudio.html#install-rstudio",
    "href": "chapter_2_rstudio.html#install-rstudio",
    "title": "2  Getting Comfortable with R and RStudio",
    "section": "2.2 Install RStudio",
    "text": "2.2 Install RStudio\nRStudio is a user-friendly interface for working with R. That means you must have R already installed for RStudio to work. Make sure you’ve successfully installed R in Step 1, then. . .\n\nGo to https://www.rstudio.com/products/rstudio/download/ to download RStudio Desktop (Open Source License). You’ll know you’re clicking the right one because it says “FREE” right above the download button.\nClick download, which takes you just down the page to where you can select the correct version under Installers for Supported Platforms (almost everyone will choose one of the first two options, RStudio for Windows or macOS).\nClick on the correct installer version, save, open once downloaded, agree to license and install like you would any other software. The version should be at least RStudio 2023.06.2 “Mountain Hydrangea”, 2023.\n\n\n\n If it installs, you should be able to find the RStudio icon in your applications.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Comfortable with R and RStudio</span>"
    ]
  },
  {
    "objectID": "chapter_2_rstudio.html#understanding-the-rstudio-environment",
    "href": "chapter_2_rstudio.html#understanding-the-rstudio-environment",
    "title": "2  Getting Comfortable with R and RStudio",
    "section": "2.3 Understanding the RStudio environment",
    "text": "2.3 Understanding the RStudio environment\n\n2.3.1 Pane layout\nThe RStudio environment consist of multiple windows. Each window consist of certain Panels\nPanels in RStudio\n\nSource\nConsole\nEnvironment\nHistory\nFiles\nPlots\nConnections\nPackages\nHelp\nBuild\nTutorial\nViewer\n\nIt is important to understand that not all panels will be used by you in routine as well as by us during the workshop. The workshop focuses on using R for healthcare professionals as a database management, visualization, and communication tool. The most common panels which requires attention are the source, console, environment, history, files, packages, help, tutorial, and viewer panels.\n\n\n2.3.2 A guided tour\nYou are requested to make your own notes during the workshop. Let us dive deep into understanding the environment further in the workshop.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Comfortable with R and RStudio</span>"
    ]
  },
  {
    "objectID": "chapter_2_rstudio.html#creating-a-project.",
    "href": "chapter_2_rstudio.html#creating-a-project.",
    "title": "2  Getting Comfortable with R and RStudio",
    "section": "2.4 Creating a project.",
    "text": "2.4 Creating a project.\nIt is important to understand that good workflows facilitate efficient database management. Lets discuss!",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Comfortable with R and RStudio</span>"
    ]
  },
  {
    "objectID": "chapter_2_rstudio.html#file-types-in-r",
    "href": "chapter_2_rstudio.html#file-types-in-r",
    "title": "2  Getting Comfortable with R and RStudio",
    "section": "2.5 File types in R",
    "text": "2.5 File types in R\nThe most common used file types are\n\n.R : Script file\n.Rmd : RMarkdown file\n.qmd : Quarto file\n.rds : Single R database file\n.RData : Multiple files in a single R database file",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Comfortable with R and RStudio</span>"
    ]
  },
  {
    "objectID": "chapter_2_rstudio.html#programming-basics.",
    "href": "chapter_2_rstudio.html#programming-basics.",
    "title": "2  Getting Comfortable with R and RStudio",
    "section": "2.6 Programming basics.",
    "text": "2.6 Programming basics.\nR is easiest to use when you know how the R language works. This section will teach you the implicit background knowledge that informs every piece of R code. You’ll learn about:\n\nFunctions and their arguments\nObjects\nR’s basic data types\nR’s basic data structures including vectors and lists\nR’s package system\n\n\n2.6.1 Functions and their arguments.\nTo do anything in R, we call functions to work for us. Take for example, we want to compute square root of 5197. Now, we need to call a function sqrt() for the same.\n\nsqrt(5197)\n\n[1] 72.09022\n\n\nImportant things to know about functions include:\n\nCode body.\n\nTyping code body and running it enables us understand what a function does in background.\n\nsqrt\n\nfunction (x)  .Primitive(\"sqrt\")\n\n\n\nRun a function.\n\nTo run a function, we need to add a parenthesis () after the code body. Within the parenthesis we add the details such as number in the above example.\n\nHelp page.\n\nPlacing a question mark before the function takes you to the help page. This is an important aspect we need to understand. When calling help page parenthesis is not placed. This help page will enable you learn about new functions in your journey!\n\n?sqrt \n\nTip:\nAnnotations are meant for humans to read and not by machines. It enables us take notes as we write. As a result, next time when you open your code even after a long time, you will know what you did last summer :)\n\nArguments are inputs provided to the function. There are functions which take no arguments, some take a single argument and some take multiple arguments. When there are two or more arguments, the arguments are separated by a comma.\n\n# No argument\nSys.Date()\n\n[1] \"2024-10-03\"\n\n# One argument\nsqrt(5197)\n\n[1] 72.09022\n\n# Two arguments\nsum(2,3)\n\n[1] 5\n\n# Multiple arguments\nseq(from=1,\n    to = 10, \n    by  = 2)\n\n[1] 1 3 5 7 9\n\n\nMatching arguments: Some arguments are understood as such by the software. Take for example, generating a sequence includes three arguments viz: from, to, by. The right inputs are automatically matched to the right argument.\n\nseq(1,10,2)\n\n[1] 1 3 5 7 9\n\n\nCaution: The wrong inputs are also matched. Best practice is to be explicit at early stages. Use argument names!\n\nseq(2,10,1)\n\n[1]  2  3  4  5  6  7  8  9 10\n\nseq(by = 2,\n    to = 10,\n    from = 1)\n\n[1] 1 3 5 7 9\n\n\nOptional arguments: Some arguments are optional. They may be added or removed as per requirement. By default these optional arguments are taken by R as default values. Take for example, in sum() function, na.rm = FALSE is an optional argument. It ensures that the NA values are not removed by default and the sum is not returned when there are NA values. These optional arguments can be override by mentioning them explicitly.\n\nsum(2,3,NA)\n\n[1] NA\n\nsum(2,3,NA, na.rm = T)\n\n[1] 5\n\n\nIn contrast, the arguments which needs to be mentioned explicitly are mandatory! Without them, errors are returned as output.\n\nsqrt()\n\n\n\n2.6.2 Objects.\nIf we want to use the results in addition to viewing them in console, we need to store them as objects. To create an object, type the name of the object (Choose wisely, let it be explicit and self explanatory!), then provide an assignment operator. Everything to the right of the operator will be assigned to the object. You can save a single value or output of a function or multiple values or an entire data set in a single object.\n\n# Single value\nx &lt;- 3\nx\n\n[1] 3\n\n# Output from function\nx &lt;- seq(from=1,\n    to = 10, \n    by  = 2)\n# Better name:\nsequence_from_1_to_10 &lt;- seq(from=1,\n    to = 10, \n    by  = 2)\n\nCreating an object helps us in viewing its contents as well make it easier to apply additional functions\nTip. While typing functions/ object names, R prompts are provided. Choose from the prompts rather than typing the entire thing. It will ease out many things later!\n\nsequence_from_1_to_10\n\n[1] 1 3 5 7 9\n\nsum(sequence_from_1_to_10)\n\n[1] 25\n\n\n\n\n2.6.3 Vectors\nR stores values as a vector which is one dimensional array. Arrays can be two dimensional (similar to excel data/ tabular data), or multidimensional. Vectors are always one dimensional!\nVectors can be a single value or a combination of values. We can create our own vectors using c() function.\n\nsingle_number &lt;- 3\nsingle_number\n\n[1] 3\n\nnumber_vector &lt;- c(1,2,3)\nnumber_vector\n\n[1] 1 2 3\n\n\nCreating personalized vectors is powerful as a lot of functions in R takes vectors as inputs.\n\nmean(number_vector)\n\n[1] 2\n\n\nVectorized functions: The function is applied to each element of the vector:\n\nsqrt(number_vector)\n\n[1] 1.000000 1.414214 1.732051\n\n\nIf we have two vectors of similar lengths (such as columns of a research data), vectorised functions help us compute for new columns by applying the said function on each element of both the vectors and give a vector of the same length (Consider this as a new column in the research data)\n\nnumber_vector2 &lt;- c(3,-4,5.4)\nnumber_vector + number_vector2\n\n[1]  4.0 -2.0  8.4\n\n\n\n\n2.6.4 Data Types\nR recognizes different types of vectors based on the values in the vector.\nIf all values are numbers (positive numbers, negative numbers, decimals), R will consider that vector as numerical and allows you to carry out mathematical operations/ functions. You can find the class of the vector by using class() function.R labels these vectors as “double”, “numeric”, or “integers”.\n\nclass(number_vector)\n\n[1] \"numeric\"\n\nclass(number_vector2)\n\n[1] \"numeric\"\n\n\nIf the values are within quotation marks, it is character variable by default. It is equivalent to nominal variable.\n\nalphabets_vector &lt;- c(\"a\", \"b\", \"c\")\nclass(alphabets_vector)\n\n[1] \"character\"\n\ninteger_vector &lt;- c(1L,2L)\nclass(integer_vector)\n\n[1] \"integer\"\n\n\nLogical vectors contain TRUE and FALSE values\n\nlogical_vector &lt;- c(TRUE, FALSE)\nclass(logical_vector)\n\n[1] \"logical\"\n\n\nFactor vectors are categorical variables. Other variable types can be converted to factor type using functionfactor()\n\nfactor_vector &lt;- factor(number_vector)\nfactor_vector\n\n[1] 1 2 3\nLevels: 1 2 3\n\n\nWe can add labels to factor vectors using optional arguments\n\nfactor_vector &lt;- factor(number_vector,\n                        levels =c(1,2,3),\n                        labels = c(\"level1\", \n                                   \"level2\", \n                                   \"level3\"))\nfactor_vector\n\n[1] level1 level2 level3\nLevels: level1 level2 level3\n\n\nOne vector = One type. For example: When there is mix of numbers and characters, R will consider all as character.\n\nmix_vector &lt;- c(1,\"a\")\nclass(mix_vector)\n\n[1] \"character\"\n\n\nNote that the number 1 has been converted into character class.\n\nmix_vector[1]\n\n[1] \"1\"\n\nmix_vector[1] |&gt; class()\n\n[1] \"character\"\n\n\nDouble, character, integer, logical, complex, raw, dates, etc… There are many other data types and objects but for now, lets start with these. You will understand additional types as you will proceed in your R journey!\n\n\n2.6.5 Lists\nIn addition to vectors, lists are another powerful objects. A list can be considered as a vector of vectors!! They enable you to store multiple types of vectors together. A list can be made using a list() function. It is similar to c() function but creates a list rather than a vector. It is a good practice to name the vectors in the list.\n\nexample_list &lt;- list(numbers = number_vector, \n                     alphabets = alphabets_vector)\nclass(example_list)\n\n[1] \"list\"\n\nexample_list\n\n$numbers\n[1] 1 2 3\n\n$alphabets\n[1] \"a\" \"b\" \"c\"\n\n\nThe elements of a named list/ a named vector can be called by using a $.\n\nexample_list$numbers\n\n[1] 1 2 3\n\n\n\n\n2.6.6 Packages\nThere are thousands of functions in R. To be computationally efficient, R do not load all functions on start. It loads only base functions. As you want to use additional functions, we need to load the packages using library() function.\n\nThe additional packages are installed once but loaded everytime you start R sessions.\nWith these basics, lets deep dive into the workshop!! Are you ready?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Comfortable with R and RStudio</span>"
    ]
  },
  {
    "objectID": "chapter_3_visualisation.html#basics",
    "href": "chapter_3_visualisation.html#basics",
    "title": "3  Data Visualization",
    "section": "3.1 Basics",
    "text": "3.1 Basics\nThe present session will focus on basics of data visualization.\n\n3.1.1 Statistical Underpinnings\nBefore we start with learning how to create graphs/ plots/ figures using R, it is important to understand that the selection of type of plots is dependent entirely upon the number and type of variables selected. Though we are not covering the bio statistics module, it is strongly recommended that the same be refreshed and strengthened by participants from time to time for advanced use of data analytics in future.\n\n\n3.1.2 Programming Basics\nData visualization is a powerful tool for data science in epidemiology. The basics of programming for creating plots using ggplot package includes understanding of four important aspects.\n\nUse of reusable/ reproducible templates.\nCreation of different types of plots using geoms.\nAddition of variables using mapping.\nCustomization of plots using settings.\n\nFor illustration of concepts, we will be using birthwt data set from MASS package which includes data on Risk Factors Associated with Low Infant Birth Weight in the present session.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapter_3_visualisation.html#about-the-dataset",
    "href": "chapter_3_visualisation.html#about-the-dataset",
    "title": "3  Data Visualization",
    "section": "3.2 About the dataset",
    "text": "3.2 About the dataset\n\nbirthwt dataset from the MASS package\n\nFor illustrative examples in the sections on data visualization, data analysis, and summary tables, Risk Factors Associated with Low Infant Birth Weight dataset (birthwt) dataset has been used. It is an inbuilt dataset from the package MASS. To load the dataset, type the following R code\n\ndf &lt;- MASS::birthwt\n\nSince, it has been labelled as df, it has been reffered as df from here on. The dataset used has 189 rows and 10 columns. The data were collected at Baystate Medical Center, Springfield, Mass during 1986. The variables present in the data includes the following variables/ columns:-\n\nlow : indicator of birth weight less than 2.5 kg\nage: mother’s age in years\nlwt: mother’s weight in pounds at last menstrual period\nrace : mother’s race (1 = white, 2 = black, 3 = other)\nsmoke : smoking status during pregnancy\nptl : number of previous premature labours\nht : history of hypertension\nui : presence of uterine irritability\nftv : number of physician visits during the first trimester\nbwt : birth weight in grams\n\n Hosmer, D.W. and Lemeshow, S. (1989) Applied Logistic Regression. New York: Wiley\n Venables, W. N. and Ripley, B. D. (2002) Modern Applied Statistics with S. Fourth edition. Springer.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapter_3_visualisation.html#load-dataset",
    "href": "chapter_3_visualisation.html#load-dataset",
    "title": "3  Data Visualization",
    "section": "3.3 Load Dataset",
    "text": "3.3 Load Dataset\n\n# install.packages(\"tidyverse\")  includes ggplot\n# install.packages(\"MASS\") includes multiple data sets for learning purposes\noptions(tidyverse.quiet = TRUE)\nlibrary(tidyverse)\ndf &lt;- MASS::birthwt\n\nData cleaning (Detailed session on Day 03)\n\ndf &lt;- df |&gt; \n  mutate(smoke = factor(smoke,\n                        levels = c(0,1),\n                        labels = c(\"Non Smoker\",\n                                   \"Smoker\"))) |&gt; \n  mutate(race = factor(race,\n                       levels = c(1,2,3),\n                       labels = c(\"White\",\n                                  \"Black\",\n                                  \"Other\"))) |&gt; \n  mutate(low = factor(low,\n                      levels =  c(0,1),\n                      labels = c(\"Normal\", \n                                 \"Low Birth Weight\")))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapter_3_visualisation.html#visualization-of-single-variable.",
    "href": "chapter_3_visualisation.html#visualization-of-single-variable.",
    "title": "3  Data Visualization",
    "section": "3.4 Visualization of single variable.",
    "text": "3.4 Visualization of single variable.\n\n3.4.1 Continous variable\nFor illustration, we will plot birth weights to understand the distribution pattern among all study participants in birth weight data set.\n\n3.4.1.1 Histogram\ngeom_histogram visualize the distribution of a single continuous variable by dividing the x axis into bins and counting the number of observations in each bin. Histograms geom_histogram() display the counts with bars\n\nggplot(data = df, aes(x = bwt)) + # Template\n  geom_histogram( # geom\n    mapping = aes(y = after_stat(density)), # mapping\n    binwidth = 350, # mandatory settings\n    color = \"blue\", # optional settings\n    fill = \"red\",\n    linetype = 1,\n    alpha = 0.5,\n    size = 1) +\n  geom_density(color = 'darkgreen', linetype = 1, linewidth = 2)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nTips\n\nColor: Determines color of the lines of histogram\nFill: Fills the histogram with specified color\nLinetype: try numbers from 0 to 6\nAlpha: Used for transparency adjustments. Varies from 0 (transparent) to 1 (Opaque)\nSize: Determines thicknes of the lines\n\n\n\n3.4.1.2 Frequency polygon\ngeom_freqpoly() display the counts with lines. Further, frequency polygons are more suitable when you want to compare the distribution across the levels of a categorical variable (we shall see later!).\n\nggplot(data = df) +\n  geom_freqpoly(mapping = aes(x = bwt),\n                binwidth = 350) # Alternative use of bins\n\n\n\n\n\n\n\n\n\n\n3.4.1.3 Dot plot\nIn a dot plot, the width of a dot corresponds to the bin width, and dots are stacked, with each dot representing one observation.\n\nggplot(data = df) +\n  geom_dotplot(mapping = aes(x = bwt),\n               binwidth = 150) \n\n\n\n\n\n\n\n\n\n\n3.4.1.4 Box and whisker plot\nThe boxplot compactly displays the distribution of a continuous variable. It visualizes five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\n\nggplot(data = df) +\n  geom_boxplot(mapping = aes(y = bwt),\n               coef = 1.5) \n\n\n\n\n\n\n\n\nWhat happens if we change the coef argument to 3?\n\n\n3.4.1.5 Density plot\ngeom_density computes and draws kernel density estimate, which is a smoothed version of the histogram. This is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\n\nggplot(data = df) + \n  geom_density(mapping = aes(x = bwt))\n\n\n\n\n\n\n\n\nTip\nMultiple plots can be combined for enhanced visualization. For example, we can combine histogram and frequency polygon.\n\n##Create a histogram and save it as an object\nhistogram &lt;- ggplot(data = df) + \n  geom_histogram( \n    mapping = aes(x = bwt), \n    binwidth = 350, \n    color = \"blue\",\n    fill = \"red\",\n    alpha = 0.2) \n##Add a frequency polygon\nhistogram +  \n  geom_freqpoly(mapping = aes(x = bwt),\n                binwidth = 350)\n\n\n\n\n\n\n\n\n\n\n\n3.4.2 Discrete/ Categorical variable.\nIllustrative example: In the birth weight dataset, if we are interested to understand the distribution of smoking history (Present/Absent) among mothers.\n\n3.4.2.1 Bar Chart \ngeom_bar() makes the height of the bar proportional to the number of cases in each group.\n\nggplot(data = df) +\n  geom_bar(mapping = aes(x = smoke)) \n\n\n\n\n\n\n\n\nAdd optional arguments (settings) to enhance visualizations.\nWhat happens if we provide y axis rather than x axis?\nWhat happens if instead of writing , we write only in the code chunk?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapter_3_visualisation.html#visualization-of-two-variables.",
    "href": "chapter_3_visualisation.html#visualization-of-two-variables.",
    "title": "3  Data Visualization",
    "section": "3.5 Visualization of two variables.",
    "text": "3.5 Visualization of two variables.\n\n3.5.1 Two continous variables.\nIllustrative example: In the birth weights dataset, mother’s weight at last menstrual period and birth weight of the infant are continuous variables. We might be interested in looking at how mother’s weight is associated with birth weight of an infant.\n\n3.5.1.1 Scatter plot\nThe geom_point is used to create scatter plots. The scatter plot is most useful for displaying the relationship between two continuous variables.\n\nggplot(data = df) + \n  geom_point(aes(x = lwt, y = bwt), \n             color = \"red\",\n             size = 1,\n             shape = 1,\n             stroke = 1) \n\n\n\n\n\n\n\n\nTips\n\nShape of a scatter plot can be changed using numbers (see below)\nStroke argument in scatter plot determines the width of the border of the shapes\nIn scatter plots, the fill argument works with selected shapes\n\n\n\n\n\n\n\nWhat happens if the size is changed to 10?\nWhen would you like to reduce the size further?\nCan we use geom_point to look at relationships between two variables, even if they are not continuous variables?\nTry using instead of . What do you observe?\n\n\n\n3.5.1.2 Scatter plot with regression line\nFurther, we can add a regression line to understand the relationship by using geom_smooth. It aids the eye in seeing patterns, especially in the presence of overplotting.\n\nggplot(data = df) +\n  geom_point(aes(x = lwt, y = bwt), \n             color = \"red\",\n             size = 1,\n             shape = 1,\n             stroke = 1) +\n  geom_smooth(aes(x = lwt, y = bwt),\n              method = lm,\n              se = T)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nTips Change the method to loess. What do you observe?\n\n\n3.5.1.3 Scatter plot with marginal plots\nYou can explore additional features with ggExtra package for marginal plots and gridExtra package for arranging multiple plots.\n\nlibrary(ggExtra)\nlibrary(gridExtra)\n\nplot &lt;- \n  ggplot(data = df) + \n  geom_point(aes(x = lwt, y = bwt), \n             color = \"red\",\n             size = 1,\n             shape = 1,\n             stroke = 1)\nplot1 &lt;- \n  ggMarginal(plot, type = \"histogram\")\nplot2 &lt;- \n  ggMarginal(plot, type = \"density\")\nplot3 &lt;- \n  ggMarginal(plot, type = \"boxplot\")\n\n# combine plots in a grid\ngrid.arrange( plot1, plot2, plot3, ncol=3)\n\n\n\n\n\n\n\n\n\n\n\n3.5.2 One discrete and one continous variable.\nIllustrative example: In the birth weights dataset, smoking history is categorical and birth weight is a continuous variable. We might be interested to estimate if maternal smoking history has effect on infant birth weights.\n\n3.5.2.1 Bar chart\nWhile using bar charts for two variables, an important additional argument which is used is stat = . Lets see!\n\nggplot(data = df) + \n  geom_bar(aes(x = smoke, y = bwt),\n           stat = \"identity\")\n\n\n\n\n\n\n\n\nAlternatively, geom_col can be used. As compared to geom_bar, since counts the number of cases at each x position, additional argument stat = is not required.\n\nggplot(data = df) + \n  geom_col(aes(x = smoke, y = bwt))\n\n\n\n\n\n\n\n\n\n\n3.5.2.2 Box and whisker plot\n\nggplot(data = df) + \n  geom_boxplot(aes(x = smoke, y = bwt),\n               coef = 1.5)\n\n\n\n\n\n\n\n\nTips Look at help menu to see additional arguments and change outlier color to red.\n\n\n3.5.2.3 Dot plot\nWhile creating a dot plot an additional mandatory argument in settings is binaxis = \" \". The axis chosen is the axis with continuous variable.\nUse geom_dotplot to create dot plot between smoking history and birth weight.\n\n\n\n3.5.3 Two discrete variables\nIllustrative example: In the dataset, smoking history and whether the infants birth weight was low or not are two discrete/ categorical variables. As a researcher, we would like to see the relationship between these two discrete variables.\n\n3.5.3.1 Position adjustments in bar chart\nTo see relationships between two discrete variables, multiple bar charts and component bar charts are used. Till now, the fill argument has been used in the setting section of the code. If you look carefully, while in the setting section, we manually placed the value/ color. The same argument can also be used in mapping section within aesthetics.\n\nggplot(data = df) + \n  geom_bar(aes(x = smoke, fill = race),\n           position = \"dodge\")\n\n\n\n\n\n\n\n\nReplace to . What happens?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapter_3_visualisation.html#visualization-of-three-variables.",
    "href": "chapter_3_visualisation.html#visualization-of-three-variables.",
    "title": "3  Data Visualization",
    "section": "3.6 Visualization of three variables.",
    "text": "3.6 Visualization of three variables.\nIllustrative example: In the birth weight dataset, a researcher is interested to look at relationship between maternal weight, smoking history, and infants birth weight.\nTip\nWhen the setting arguments are shifted to mapping section, the computer automatically maps the value to develop the plot.\nTo visualize three or more variables, the settings arguments of color, shape, and size can be shifted to mapping section of the template we were using. Lets see!\n\nggplot(data = df) + \n  geom_point(aes(x = lwt, y = bwt, color = smoke))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapter_3_visualisation.html#visualization-of-four-variables.",
    "href": "chapter_3_visualisation.html#visualization-of-four-variables.",
    "title": "3  Data Visualization",
    "section": "3.7 Visualization of four variables.",
    "text": "3.7 Visualization of four variables.\nNow, lets see whether the race of mother is also playing a role in addition to her weight and smoking history in determining birth weight of the child\n\nggplot(data = df) + \n  geom_point(aes(x = lwt, y = bwt, \n                 color = smoke, \n                 shape = factor(race)),\n             size = 3)\n\n\n\n\n\n\n\n\nFor incorporating additional variables, multiple approaches such as 3D visualizations, animations, facet charts, etc can be used. For further details, refer to https://exts.ggplot2.tidyverse.org/gallery/",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapter_3_visualisation.html#facet-plots.",
    "href": "chapter_3_visualisation.html#facet-plots.",
    "title": "3  Data Visualization",
    "section": "3.8 Facet plots.",
    "text": "3.8 Facet plots.\nfacet_grid() forms a matrix of panels defined by row and column faceting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data. If you have only one variable with many levels, try facet_wrap().\n\nggplot(data = df) + \n  geom_point(aes(x = lwt, y = bwt, color = smoke))+\n  facet_grid(.~race)\n\n\n\n\n\n\n\n\n\nWhat happens if we change to \nUse facet_wrap instead of facet_grid. What do you observe?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapter_3_visualisation.html#way-forward",
    "href": "chapter_3_visualisation.html#way-forward",
    "title": "3  Data Visualization",
    "section": "3.9 Way forward",
    "text": "3.9 Way forward\n\n3.9.1 Additional components\nNow, we know how to create the plot. However, plot has additional components such as title, subtitle, caption, axis labels, legend, etc. The same also requires deliberation and details for the same can be learnt from multiple resources. We recommend R Graphics Cookbook https://r-graphics.org/ as a good resource for the same. We are introducing you to this important aspect of data visualization, however considering the present workshop as an introductory workshop and with time constraints, we plan to cover these aspects during intermediate/ advanced levels only.\n\nggplot(data = df) + # Template\n  geom_freqpoly( # geom\n    mapping = aes(x = bwt, color = smoke), # mapping\n    binwidth = 400,\n    size = 1.5)  + \n  labs(title = \"Birth weight and maternal smoking\", # Title\n       subtitle = \"Density plots\", # Subtitle\n       caption = \"Source: Low Birth Weight data (MASS)\", # Caption\n       x = \"Birth Weights (grams)\", # x axis label\n       y = \"Frequency\",# y axis label\n       color = \"Maternal Smoking history\")  + # Legend title\n  geom_text(x = 2400, # Additional text in the plot\n            y = 10, \n            label = \" Ideal Birth weight\", \n            color = \"#990000\", # RGB color coding palette\n            angle = 90,\n            alpha = .5,)+\n  geom_vline(xintercept= 2500, colour=\"#009900\") + # Line insert \n  theme(legend.position = \"left\") + # Legend settings\n  theme_minimal() # Choosing background theme\n\n\n\n\n\n\n\n\n\n\n3.9.2 Maps\nR is a powerful programming language. It has capabilities to create its own GIS environment. Though spatial analytics including spatial data visualization requires additional packages, to introduce the domain, we shall be using India spatial file and make a basic map within the tidyverse!\n\n\n\n\n\n\n\n\n\nSince the map provided as demo is against the cartographic principles, despite being an introductory module, we would like you to get an exposure of cartographically correct map too!\n\n\n\n\n\n\n\n3.9.3 Visual analytics\nThe domain of data visualization has gone beyond just visualizing data. Visual analytics and data visualization is now used across the data life cycle in epidemiology and health care. It has moved beyond descriptive epidemiology and is used for hypothesis testing, machine learning, artificial intelligence, time series analysis, spatio-temporal epidemiology, and many others.\nHope you have enjoyed the session! The Jump board is ready! Practice and see the power of visual analytics!! Best Wishes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapter_4_working_with_data.html#before-we-get-started",
    "href": "chapter_4_working_with_data.html#before-we-get-started",
    "title": "4  Fundamentals of working with Data",
    "section": "4.1 Before we get started",
    "text": "4.1 Before we get started\nLet us recap once again creating a project in R. It is a best practice to use create a project for each data analysis you are planning to perform. You can create a New Project using the File menu in RStudio. Let us create one now!\nReading and writing files often involves the use of file paths. A file path is a string of characters that point R and RStudio to the location of the file on your computer.\nThese file paths can be a complete location2 or just the file name.3 If you pass R a partial file path, R will append it to the end of the file path that leads to your working directory. The working directory is the directory where your .Rproj file is.\nRun here::here() to see the file path that leads to your current working directory.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fundamentals of working with Data</span>"
    ]
  },
  {
    "objectID": "chapter_4_working_with_data.html#importing-data-using-the-rstudio-gui",
    "href": "chapter_4_working_with_data.html#importing-data-using-the-rstudio-gui",
    "title": "4  Fundamentals of working with Data",
    "section": "4.2 Importing data using the RStudio GUI",
    "text": "4.2 Importing data using the RStudio GUI\nThe RStudio IDE provides an Import Dataset button in the Environment pane, which appears in the top right corner of the IDE by default. You can use this button to import data that is stored in plain text files as well as in Excel, SAS, SPSS, and Stata files.\n\n\n\n\n\nWe recommend using .csv file type to read and write your data as a best practice. This will ensure cross compatibility between various programs as it is just a raw text file but just separated by a comma.\n\n\n\n\n\n\n\nNote\nThere are different packages to import different types of data.\n\nhaven : SPSS, Stata, or SAS\nreadxl : Excel spreadsheets\nreadr : csv, txt, tsv etc.\n\nHowever, we recommend using the rio package.\nThere are two main functions in the rio package, import() and export(). The import() function takes the file path as an input argument, while the export() function takes the object and destination file path as arguments.\nThe import() function has an additional argument setclass which needs to be set to tibble to import the data as a tibble (the workhorse of tidyverse workflows).\nThere are a number of differences between tibbles and data.frames. To see a full vignette about tibbles and how they differ from data.frame, please run vignette(\"tibble\") in the console and read through that vignette.\n\n\n\n\n\n\n\nSome major differences are:\n\nInput type remains unchanged - data.frame changes strings as factors; tibble will not\nVariable names remain unchanged - data.frame will remove spaces or add “x” before numeric column names. tibble will not.\nThere are no row.names() for a tibble\ntibble print first ten rows and columns that fit on one screen\n\n\nExercise\n\nImport the provided .csv file into the RStudio environment using the method mentioned above.\nCan you see anything apprearing on the RStudio Console pane once you have imported the file?\nCan you see anything apprearing on the RStudio Environment pane once you have imported the file?\nImport the provided .xls file into the RStudio environment using the method mentioned above.\nChange the sheet to import as well as skip the first row. See the changes happen in the R code syntax in the bottom right pane of the GUI",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fundamentals of working with Data</span>"
    ]
  },
  {
    "objectID": "chapter_4_working_with_data.html#saving-and-loading-a-compressed-.rds-file",
    "href": "chapter_4_working_with_data.html#saving-and-loading-a-compressed-.rds-file",
    "title": "4  Fundamentals of working with Data",
    "section": "4.3 Saving and Loading a compressed .rds file",
    "text": "4.3 Saving and Loading a compressed .rds file\n.rds is a file format native to R for saving compressed content. .rds files are not text files and are not human readable in their raw form. Each .rds file contains a single object, which makes it easy to assign its output directly to a single R object. This is not necessarily the case for .RData files, which makes .rds files safer to use.\nUse the write_rds() function from the readr package to write an .rds file. Save the previously loaded data, as an .rds file using this function. You can look at the help menu to know more on the syntax or you can type ?write_rds in the Console pane.\nNow you can open your file explorer go to your working directory and check if the file has been saved. Similarly, you can use the write_csv() function from the readr package to write a .csv file.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fundamentals of working with Data</span>"
    ]
  },
  {
    "objectID": "chapter_4_working_with_data.html#principles-of-tidy-data",
    "href": "chapter_4_working_with_data.html#principles-of-tidy-data",
    "title": "4  Fundamentals of working with Data",
    "section": "4.4 Principles of Tidy Data",
    "text": "4.4 Principles of Tidy Data\n\n4.4.1 What is Tidy Data?\n\nTidy data is a way to describe data that’s organized with a particular structure – a rectangular structure, where each variable has its own column, and each observation has its own row. — Hadley Wickham, 2014\n\n\n\n4.4.2 Three Rules of Tidy Data\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\nThese three rules are interrelated because it’s impossible to only satisfy two of the three.\n\n\n\n\n\n\n\n\n\n4.4.3 Messy Data vs Tidy Data\n\nTidy datasets are all alike, but every messy dataset is messy in its own way. - Hadley Wickham\n\n\n\n\nSource: R for Data Science (http://r4ds.had.co.nz/)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with messy data can be messy!. You need to build custom tools from scratch each time you work with a new dataset.\nIllustrations from : https://github.com/allisonhorst/stats-illustrations\n\n\n4.4.4 Tidy data for more efficient data science\nPackages like tidyr and dplyr can enable you to get on with analysing your data and start answering key questions rather than spending time in trying to clean the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\nTidy data allows you to be more efficient by using specialised tools built for the tidy workflow. There are a lot of tools specifically built to wrangle untidy data into tidy data.\n\n\n\n\n\nOne other advantage of working with Tidy data is that it makes it easier for collaboration, as your colleagues can use the same familiar tools rather than getting overwhelmed with all the work you did from scratch. It is also helpful for your future self as it becomes a consistent workflow and takes less adjustment time for any incremental changes.\nTidy data also makes it easier to reproduce analyses because they are easier to understand, update, and reuse. By using tools together that all expect tidy data as inputs, you can build and iterate really powerful workflows.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fundamentals of working with Data</span>"
    ]
  },
  {
    "objectID": "chapter_4_working_with_data.html#a-word-on-tibble",
    "href": "chapter_4_working_with_data.html#a-word-on-tibble",
    "title": "4  Fundamentals of working with Data",
    "section": "4.5 A word on Tibble",
    "text": "4.5 A word on Tibble\nWhen loading data into R using the RStudio GUI using tidyverse, the data is automatically saved as a tibble. A tibble is a data frame, but they have some new functionalities and properties to make our life easier. It is the single most important workhorse of tidyverse.\n\n\n\ntibble() vs data.frame()\n\n\nYou can change data.frame objects to a tibble using the as_tibble() function.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fundamentals of working with Data</span>"
    ]
  },
  {
    "objectID": "chapter_4_working_with_data.html#working-with-tibbles",
    "href": "chapter_4_working_with_data.html#working-with-tibbles",
    "title": "4  Fundamentals of working with Data",
    "section": "4.6 Working with Tibbles",
    "text": "4.6 Working with Tibbles\nNow that you have imported data into RStudio its a good practice to have a look at the data. There are many ways you can do it within RStudio.\n\nThrough the Environment pane\nView() function\nSimply typing the name of the dataset in the Console\n\nSome other things you can do to have a look at your data are:\n\nChecking the class of the dataset using class() function\nChecking the structure of the dataset using str() function\n\nNote\nclass() and str() are not just limited to datasets, they can be used for any R objects.\nSome additional tips for quickly looking at your data:\n\nhead()\ntail()\nglimpse()\n\n\nExercise\n\nType the name of the dataset in the console and see what happens?\nHow many rows and columns can you visualize?\nNow, try the head(), tail(), and glimpse() functions\nTry to create a tibble manually in RStudio with a numeric, character, and factor variable. (Hint: vignette(‘tibble’) )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fundamentals of working with Data</span>"
    ]
  },
  {
    "objectID": "chapter_5_exploring_data.html#getting-started-with-the-data-exploration-pipeline",
    "href": "chapter_5_exploring_data.html#getting-started-with-the-data-exploration-pipeline",
    "title": "5  Exploring Data with R",
    "section": "5.1 Getting Started with the Data Exploration Pipeline",
    "text": "5.1 Getting Started with the Data Exploration Pipeline\nToday we will be working in a RMarkdown Document (*.Rmd). This is one of the recommended practices when working with data analysis projects. RMarkdown interweaves prose with code. Prose are written in plain text and R code is contained in gray “r code chunks”.\nLet’s write our first R code. To insert a new R code chunk press Ctrl+Alt+I OR CMD+Option+I.\n\n# R can work as a basic calculator &lt;- this is a code comment\n5 + 3\n\n[1] 8\n\n\n\n5.1.1 Set-up\n\n# Load the required packages\nlibrary(tidyverse) # required for tidy workflows\nlibrary(rio) # required for importing and exporting data\nlibrary(here) # required for managing file paths\n\nhere() starts at C:/Users/Arun/Dropbox/PhD/Workshops/AIIMS_Mangalagiri/NWHDA_Mangalagiri\n\n\nNote\nThe shortcut for code commenting is Ctrl+Shift+C. Try doing it in the code cunk and the text part.\n\n\n5.1.2 Load Data\n\n\n\n\nThe dataset we will be working with has been cleaned (to an extent) for the purposes of this workshop. It is a dataset about tuberculosis that has been downloaded from the World Health Organization and cleaned up for our use. The raw dataset and many more such data are publicly available at: https://www.who.int/teams/global-tuberculosis-programme/data for download.\n\n\n# Check the file path\nhere::here(\"data\", \"who_tubercolosis_data.csv\")\n\n[1] \"C:/Users/Arun/Dropbox/PhD/Workshops/AIIMS_Mangalagiri/NWHDA_Mangalagiri/data/who_tubercolosis_data.csv\"\n\n# Read Data\ntb &lt;- rio::import(\n  here::here(\"data\", \"who_tubercolosis_data.csv\"), setclass = 'tibble')\n\nTry the following functions using tb as the argument:\n\nglimpse()\nhead()\nnames()\n\nToday, we will be introducing you to three new packages:\n\ndplyr\nskimr\nDataExplorer",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Exploring Data with R</span>"
    ]
  },
  {
    "objectID": "chapter_5_exploring_data.html#dplyr-package",
    "href": "chapter_5_exploring_data.html#dplyr-package",
    "title": "5  Exploring Data with R",
    "section": "5.2 dplyr Package",
    "text": "5.2 dplyr Package\nThe dplyr is a powerful R-package to manipulate, clean and summarize unstructured data. In short, it makes data exploration and data manipulation easy and fast in R.\n\n\n\n\n\n\n\nThere are many verbs in dplyr that are useful, some of them are given here…\n\n\n\nImportant functions of the dplyr package to remember\n\n\n\n\n\nSyntax structure of the dplyr verb\n\n\n\n5.2.1 Getting used to the pipe |&gt; or %&gt;%\n\n\n\nThe pipe operator in dplyr\n\n\nNote\nThe pipe |&gt; means THEN…\nThe pipe is an operator in R that allows you to chain together functions in dplyr.\nLet’s find the bottom 50 rows of tb without and with the pipe.\nTips The native pipe |&gt; is preferred.\n\n#without the pipe\ntail(tb, n = 50)\n\n#with the pipe\ntb |&gt; tail(n = 50)\n\nNow let’s see what the code looks like if we need 2 functions. Find the unique countries in the bottom 50 rows of tb.\n\n#without the pipe\nunique(tail(tb, n = 50)$country)\n\n# with the pipe\ntb |&gt; \n  tail(50) |&gt;\n  distinct(country)\n\nNote\nThe shortcut for the pipe is Ctrl+Shift+M\nYou will notice that we used different functions to complete our task. The code without the pipe uses functions from base R while the code with the pipe uses a mixture (tail() from base R and distinct() from dplyr). Not all functions work with the pipe, but we will usually opt for those that do when we have a choice.\n\n\n5.2.2 distinct() and count()\nThe distinct() function will return the distinct values of a column, while count() provides both the distinct values of a column and then number of times each value shows up. The following example investigates the different regions (who_region) in the tb dataset:\n\ntb |&gt; \n  distinct(who_region) \n\ntb |&gt; \n  count(who_region)\n\nNotice that there is a new column produced by the count function called n.\n\n\n5.2.3 arrange()\nThe arrange() function does what it sounds like. It takes a data frame or tbl and arranges (or sorts) by column(s) of interest. The first argument is the data, and subsequent arguments are columns to sort on. Use the desc() function to arrange by descending.\nThe following code would get the number of times each region is in the dataset:\n\ntb |&gt; \n  count(who_region) |&gt; \n  arrange(n)\n\n# Since the default is ascending order, \n# we are not getting the results that are probably useful, \n# so let's use the desc() function\ntb |&gt; \n  count(who_region) |&gt; \n  arrange(desc(n))\n\n# shortcut for desc() is -\ntb |&gt; \n  count(who_region) |&gt; \n  arrange(-n)\n\n\nExercise\n\n“How many countries are there in the tb dataset?\nWhich countries have fewer than 18 rows of data?\nWhich country in which year has the highest tb incidence per 100k?\nWhich country in which year has the highest tb incidence number?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.2.4 filter()\nIf you want to return rows of the data where some criteria are met, use the filter() function. This is how we subset in the tidyverse. (Base R function is subset())\n\n\n\n\n\n\n\nHere are the logical criteria in R:\n\n==: Equal to\n!=: Not equal to\n&gt;: Greater than\n&gt;=: Greater than or equal to\n&lt;: Less than\n&lt;=: Less than or equal to\n\nIf you want to satisfy all of multiple conditions, you can use the “and” operator, &.\nThe “or” operator | (the vertical pipe character, shift-backslash) will return a subset that meet any of the conditions.\nLet’s see all the data from 2015 or more recent\n\ntb |&gt; \n  filter(year &gt;= 2015)\n\nLet’s just see data from India\n\ntb |&gt; \n  filter(country == \"India\")\n\nBoth India and 2015 or more recent\n\ntb |&gt; \n  filter(year &gt;= 2015 & country == \"India\")\n\nWhich countries have incidence_100k below 5?\n\ntb |&gt; \n  filter(incidence_100k &lt; 5) |&gt; \n  distinct(country)\n\n# see them all\ntb |&gt; \n  filter(incidence_100k &lt; 5) |&gt; \n  distinct(country) |&gt;\n  print(n = Inf)\n\n\n\n5.2.5 %in%\nTo filter() a categorical variable for only certain levels, we can use the %in% operator.\nLet’s see data from India, Nepal, Pakistan and Bangladesh First we will have to figure out how those are spelled in this dataset. Open the spreadsheet viewer and find out. We’ll see a way to find them in code later on in the course.\nOk, so we figured out that they are spelled:\n\n“India”\n“Nepal”\n“Pakistan”\n“Bangladesh”\n\nNow we’ll create a vector of countries we are interested in\n\nindian_subcont &lt;- c(\"India\",\n           \"Nepal\",\n           \"Pakistan\",\n           \"Bangladesh\")\n\nAnd use that vector to filter() tb for countries %in% indian_subcont\n\ntb |&gt; filter(country %in% indian_subcont)\n\nYou can also save the results of a pipeline. Notice that the rows belonging to Indian Subcontinent are returned in the console. If we wanted to do something with those rows, it might be helpful to save them as their own dataset. To create a new object, we use the &lt;- operator.\n\nindian_subcont_tb &lt;- tb |&gt; filter(country %in% indian_subcont)\n\n\n\n5.2.6 drop_na()\nThe drop_na() function is extremely useful for when we need to subset a variable to remove missing values.\nReturn the tb dataset without rows that were missing on the hiv_incidence_100k variable\n\ntb |&gt; drop_na(hiv_incidence_100k)\n\nReturn the tb dataset without any rows that had an NA in any column. *Use with caution because this will remove a lot of data\n\ntb |&gt; drop_na()\n\n\n\n5.2.7 select()\nWhereas the filter() function allows you to return only certain rows matching a condition, the select() function returns only certain columns. The first argument is the data, and subsequent arguments are the columns you want.\nSee just the country, year, incidence_100k columns\n\n# list the column names you want to see separated by a comma\ntb |&gt; \n  select(country, year, incidence_100k)\n\nUse the - sign to drop these same columns\n\ntb |&gt; \n  select(-country, -year, -incidence_100k)\n\n\n\n5.2.8 select() helper functions\nThe starts_with(), ends_with() and contains() functions provide very useful tools for dropping/keeping several variables at once without having to list each and every column you want to keep. The function will return columns that either start with a specific string of text, ends with a certain string of text, or contain a certain string of text.\n\n# these functions are all case sensitive\ntb |&gt;  \n  select(starts_with(\"percent\"))\n\ntb |&gt; \n  select(ends_with(\"r\"))\n\ntb |&gt; \n  select(contains(\"_\"))\n\n# columns that do not contain -\ntb |&gt; \n  select(-contains(\"_\"))\n\n\n\n5.2.9 summarize()\nThe summarize() function summarizes multiple values to a single value. On its own the summarize() function doesn’t seem to be all that useful. The dplyr package provides a few convenience functions called n() and n_distinct() that tell you the number of observations or the number of distinct values of a particular variable.\nNote summarize() is the same as summarise()\nNotice that summarize takes a data frame and returns a data frame. In this case it’s a 1x1 data frame with a single row and a single column.\n\ntb |&gt; \n  summarize(mean(hiv_percent))\n\n# watch out for nas. Use na.rm = TRUE to run the calculation after excluding nas.\ntb |&gt; \n  summarize(mean(hiv_percent, na.rm = TRUE))\n\nThe name of the column is the expression used to summarize the data. This usually isn’t pretty, and if we wanted to work with this resulting data frame later on, we’d want to name that returned value something better.\n\ntb |&gt; \n  summarize(hiv_percent = mean(hiv_percent, na.rm = TRUE))\n\n\n\n5.2.10 group_by()\nWe saw that summarize() isn’t that useful on its own. Neither is group_by(). All this does is takes an existing data frame and converts it into a grouped data frame where operations are performed by group.\n\ntb |&gt; \n  group_by(year)\n\ntb |&gt; \n  group_by(year, who_region)\n\n\n\n5.2.11 group_by() and summarize() together\nThe real power comes in where group_by() and summarize() are used together. First, write the group_by() statement. Then pipe the result to a call to summarize().\nLet’s summarize the mean incidence of tb for each year\n\ntb |&gt; \n  group_by(year) |&gt; \n  summarize(mean_inc = mean(incidence_100k, na.rm = TRUE))\n\n#sort the output by descending mean_inc\ntb |&gt; \n  group_by(year) |&gt; \n  summarize(mean_inc = mean(incidence_100k, na.rm = TRUE)) |&gt; \n  arrange(desc(mean_inc))\n\n\n\n5.2.12 mutate()\nMutate creates a new variable or modifies an existing one.\n\n\n\n\n\n\n\nLets create a column called ind_sub if the country is in the Indian Subcontinent.\n\n# use our vector indian_subcont that we created before\ntb |&gt; \n  mutate(indian_sub1 = if_else(country %in% indian_subcont, \n                              \"Indian Subcontinent\", \"Others\"))\n\nThe same thing can be done using case_when().\n\ntb |&gt; \n  mutate(indian_sub2 = case_when(country %in% \n                                   indian_subcont ~ \n                                   \"Indian Subcontinent\",\n                           TRUE ~ \"Other\")) \n\nLets do it again, but this time let us make it 1 and 0, 1 if it is a country in the Indian Subcontinent, 0 if otherwise.\n\ntb |&gt; \n  mutate(indian_sub3 = case_when(country %in% indian_subcont ~ 1,\n                           TRUE ~ 0))\n\n\n\n\n\n\n\n\nNote\nThe if_else() function may result in slightly shorter code if you only need to code for 2 options. For more options, nested if_else() statements become hard to read and could result in mismatched parentheses so case_when() will be a more elegant solution.\nAs a second example of case_when(), let’s say we wanted to create a new population variable that is low, medium, or high.\nSee the pop broken into 3 equally sized portions\n\nquantile(tb$pop, prob = c(.33, .66))\n\nNote\nSee the help file for quanile function or type ?quantile in the console.\nWe’ll say:\n\nlow pop = 2043237 or less\nmed pop = between 2043237 and 11379155\nhigh pop = above 11379155\n\n\ntb |&gt; \n  mutate(popcat = case_when(pop &lt;= 2043237 ~ \"low\",\n                            pop &gt; 2043237 & pop &lt;= 11379155 ~ \"med\",\n                            TRUE ~ \"high\"))\n\n\n\n5.2.13 join()\nTypically in a data science or data analysis project one would have to work with many sources of data. The researcher must be able to combine multiple datasets to answer the questions he or she is interested in. Collectively, these multiple tables of data area called relational data because more than the individual datasets, its the relations that are more important.\nAs with the other dplyr verbs, there are different families of verbs that are designed to work with relational data and one of the most commonly used family of verbs are the mutating joins.\n\n\n\nDifferent type of joins, represented by a series of Venn Diagram\n\n\nThese include:\n\nleft_join(x, y) which combines all columns in data frame x with those in data frame y but only retains rows from x.\nright_join(x, y) also keeps all columns but operates in the opposite direction, returning only rows from y.\nfull_join(x, y) combines all columns of x with all columns of y and retains all rows from both data frames.\ninner_join(x, y) combines all columns present in either x or y but only retains rows that are present in both data frames.\nanti_join(x, y) returns the columns from x only and retains rows of x that are not present in y.\nanti_join(y, x) returns the columns from y only and retains rows of y that are not present in x.\n\n\n\n\nVisual representation of the join() family of verbs\n\n\nApart from specifying the data frames to be joined, we also need to specify the key column(s) that is to be used for joining the data. Key columns are specified with the by argument, e.g. inner_join(x, y, by = \"subject_id\") adds columns of y to x for all rows where the values of the “subject_id” column (present in each data frame) match. If the name of the key column is different in both the dataframes, e.g. “subject_id” in x and “subj_id” in y, then you have to specify both names using by = c(\"subject_id\" = \"subj_id\").\n\n\n5.2.14 pivot()\nMost often, when working with our data we may have to reshape our data from long format to wide format and back. We can use the pivot family of functions to achieve this task. What we mean by “the shape of our data” is how the values are distributed across rows or columns. Here’s a visual representation of the same data in two different shapes:\n\n\n\nLong and Wide format of our data\n\n\n\n“Long” format is where we have a column for each of the types of things we measured or recorded in our data. In other words, each variable has its own column.\n“Wide” format occurs when we have data relating to the same measured thing in different columns. In this case, we have values related to our “metric” spread across multiple columns (a column each for a year).\n\nLet us now use the pivot functions to reshape the data in practice. The two pivot functions are:\n\npivot_wider(): from long to wide format.\npivot_longer(): from wide to long format.\n\n\n\n\n\n\n\n\nResources for learning more dplyr\n\nCheck out the Data Wrangling cheatsheet that covers dplyr and tidyr functions.(https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)\nReview the Tibbles chapter of the excellent, free R for Data Science book.(https://r4ds.had.co.nz/tibbles.html)\nCheck out the Transformations chapter to learn more about the dplyr package. Note that this chapter also uses the graphing package ggplot2 which we have covered yesterday.(https://r4ds.had.co.nz/transform.html)\nCheck out the Relational Data chapter to learn more about the joins.(https://r4ds.had.co.nz/relational-data.html)\n\n\n\nExercise\n\n\nIn 2007, which 10 countries had the highest incidence_100k?\nWithin the South East Asia who_region, which countries have incidence_100K &gt; 300?\nHow many countries are in each who_region? Put the output in order from lowest to highest number of countries. Hint: use distinct() and arrange()\nWhich country in which year has the highest incidence of tuberculosis?\nExcluding missing values on hiv_incidence_100k, what is the correlation coefficient for the relationship between the tb incidence_100k and the hiv_incidence_100k for each region. Show the output with the highest correlations first. Hint: use cor()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Exploring Data with R</span>"
    ]
  },
  {
    "objectID": "chapter_5_exploring_data.html#skimr-package",
    "href": "chapter_5_exploring_data.html#skimr-package",
    "title": "5  Exploring Data with R",
    "section": "5.3 skimr Package",
    "text": "5.3 skimr Package\nskimr is designed to provide summary statistics about variables in data frames, tibbles, data tables and vectors. The core function of skimr is the skim() function, which is designed to work with (grouped) data frames, and will try coerce other objects to data frames if possible.\n\n\n\n\n\n\n\nGive skim() a try.\n\ntb |&gt; skimr::skim()\n\nCheck out the names of the output of skimr\n\ntb |&gt; skimr::skim() |&gt; names()\n\nAlso works with dplyr verbs\n\ntb |&gt; group_by(who_region) |&gt; skimr::skim()\n\n\ntb |&gt; skimr::skim() |&gt; \n  dplyr::select(skim_type, skim_variable, n_missing)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Exploring Data with R</span>"
    ]
  },
  {
    "objectID": "chapter_5_exploring_data.html#dataexplorer-package",
    "href": "chapter_5_exploring_data.html#dataexplorer-package",
    "title": "5  Exploring Data with R",
    "section": "5.4 DataExplorer Package",
    "text": "5.4 DataExplorer Package\nThe DataExplorer package aims to automate most of data handling and visualization, so that users could focus on studying the data and extracting insights.1\n\n\n\n\n\n\n\nThe single most important function from the DataExplorer package is create_report()\nTry it for yourself.\n\nlibrary(DataExplorer)\ncreate_report(tb)\n\n\nExercise\n\nCreate a report on Exploratory Data Analysis using RMarkdown\nUse DataExplorer to explore the given data",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Exploring Data with R</span>"
    ]
  },
  {
    "objectID": "chapter_7_summary_tables_v2.html#publicaton-ready-summary-tables",
    "href": "chapter_7_summary_tables_v2.html#publicaton-ready-summary-tables",
    "title": "6  Summary Tables",
    "section": "6.1 Publicaton ready summary tables",
    "text": "6.1 Publicaton ready summary tables\n\n6.1.1 Rationale\nIn routine, it is very time consuming, frustrating, and error prone to write again the results/ outputs obtained from statistical software into the writing and communication documents, be it an article/ manuscript or a dissertation or a thesis.\nFurther, Most courses and tutorials on Data Analytics using R teach a bunch of R functions but do not lead us to the outcome, which is to produce analyzed tables.\nIn R, there are certain packages which enable you to create publication ready tables which can be incorporated into research dissemination documents directly or with minor modifications. This saves a lot of mundane and unnecessary work and provides more time for interpretation and domain expertise related work.\nWe shall be using the gtsummary package which is compatible with tidy principles of working and creates presentation-ready tables, regression models, and more. The code to create the tables is concise and highly customizable.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summary Tables</span>"
    ]
  },
  {
    "objectID": "chapter_7_summary_tables_v2.html#introduction-to-publication-ready-tables",
    "href": "chapter_7_summary_tables_v2.html#introduction-to-publication-ready-tables",
    "title": "6  Summary Tables",
    "section": "6.2 Introduction to publication ready tables!!",
    "text": "6.2 Introduction to publication ready tables!!\nThe tbl_summary() function calculates descriptive statistics for continuous, categorical, and dichotomous variables in R, and presents the results in a beautiful, customizable summary table ready for publication. To introduce tbl_summary() we will show the most basic behaviour first, which actually produces a large and beautiful table. Then, we will examine in detail how to make adjustments and more tailored tables.The default behavior of tbl_summary() is quite incredible - it takes the columns you provide and creates a summary table in one command. The function prints statistics appropriate to the column class: median and inter-quartile range (IQR) for numeric columns, and counts (%) for categorical columns. Missing values are converted to ‘Unknown’.\nIllustrative example: A researcher is interested to know the basic descriptive analysis of the first five variables in low birth weight data.\n\ndf |&gt;  \n  select(low, bwt) |&gt;\n  tbl_summary() |&gt;  \n  as_hux_table()\n\n\n\nCharacteristic\nN = 189\n\n\nlow\n\nNormal130 (69%)\n\nLow Birth Weight59 (31%)\n\nbwt2,977 (2,414, 3,487)\n\nn (%); Median (Q1, Q3)\n\n\n\n\nNote\nThe sensible defaults with this basic usage: each of the defaults may be customized. Variable types are automatically detected so that appropriate descriptive statistics are calculated. Label attributes from the data set are automatically printed. Missing values are listed as “Unknown” in the table. Variable levels are indented and footnotes are added.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summary Tables</span>"
    ]
  },
  {
    "objectID": "chapter_7_summary_tables_v2.html#adjustments",
    "href": "chapter_7_summary_tables_v2.html#adjustments",
    "title": "6  Summary Tables",
    "section": "6.3 Adjustments",
    "text": "6.3 Adjustments\n\n6.3.1 Stratified tables.\nYou can stratify your table by a column (e.g. by outcome), creating a 2-way table by using by = argument in the tbl_summary() function.\n\ndf |&gt;  \n  select(smoke, low) |&gt; \n  tbl_summary(by = low) |&gt;  as_hux_table()\n\n\n\nCharacteristic\nNormal\nN = 130\nLow Birth Weight\nN = 59\n\n\nsmoke\n\nNon Smoker86 (66%)29 (49%)\n\nSmoker44 (34%)30 (51%)\n\nn (%)\n\n\n\n\n\n\n6.3.2 Customizing output of selected variables.\nUse an equations to specify which statistics to show and how to display them. There are two sides to the equation, separated by a tilde ~. On the right side, in quotes, is the statistical display desired, and on the left are the columns to which that display will apply.\n\ndf |&gt; \n  select(bwt, low) |&gt;\n  tbl_summary(\n    by = low,\n    statistic = bwt~\"{mean}\"\n  ) |&gt; \n  as_hux_table()\n\n\n\nCharacteristic\nNormal\nN = 130\nLow Birth Weight\nN = 59\n\n\nbwt3,3292,097\n\nMean\n\n\n\n\n\ndf |&gt; \n  select(bwt, low) |&gt;\n  tbl_summary(\n    by = low,\n    statistic = bwt~\"{mean}, {sd}\"\n  ) |&gt; \n  as_hux_table()\n\n\n\nCharacteristic\nNormal\nN = 130\nLow Birth Weight\nN = 59\n\n\nbwt3,329, 4782,097, 391\n\nMean, SD\n\n\n\n\n\n\n6.3.3 Changing label of a single variable.\nAdjust how the column name should be displayed. Provide the column name and its desired label separated by a tilde. The default is the column name. This is done with help of argument label = in tbl_summary function.\n\ndf |&gt; \n  select(bwt, low) |&gt;\n  tbl_summary(\n    by = low,\n    statistic = bwt~\"{mean}, {sd}\",\n    label = bwt ~ \"Birth Weight\"\n  ) |&gt; as_hux_table()\n\n\n\nCharacteristic\nNormal\nN = 130\nLow Birth Weight\nN = 59\n\n\nBirth Weight3,329, 4782,097, 391\n\nMean, SD\n\n\n\n\n\n\n6.3.4 Changing labels of multiple variables.\nYou can change labels of multiple variables by providing the labels as a list to the label argument.\n\ndf |&gt; \n  select(bwt, low, smoke) |&gt;\n  tbl_summary(\n    by = low,\n    statistic = bwt~\"{mean}, {sd}\",\n    label = list(bwt ~ \"Birth Weight\",\n                 smoke ~ \"Smoking history\")) |&gt; as_hux_table()\n\n\n\nCharacteristic\nNormal\nN = 130\nLow Birth Weight\nN = 59\n\n\nBirth Weight3,329, 4782,097, 391\n\nSmoking history\n\nNon Smoker86 (66%)29 (49%)\n\nSmoker44 (34%)30 (51%)\n\nMean, SD; n (%)\n\n\n\n\nCan we provide a list to the statistic argument also for customizing statistical output? Try it!\n\n\n6.3.5 Multiline output for a single variable.\nIf you want to print multiple lines of statistics for variables, you can indicate this by setting the type = to “continuous2”. You can combine all of the previously shown elements in one table by choosing which statistics you want to show. To do this you need to tell the function that you want to get a table back by entering the type as continuous2.\n\ndf |&gt; \n  select(bwt, low, smoke) |&gt;\n  tbl_summary(\n    by = low,\n    type = bwt ~ \"continuous2\",\n    statistic = bwt~c(\n      \"{mean}, {sd}\",\n      \"{median}, ({p25}, {p75})\"),\n    label = list(bwt ~ \"Birth Weight\",\n                 smoke ~ \"Smoking history\")) |&gt; as_hux_table()\n\n\n\nCharacteristic\nNormal\nN = 130\nLow Birth Weight\nN = 59\n\n\nBirth Weight\n\nMean, SD3,329, 4782,097, 391\n\nMedian, (Q1, Q3)3,267, (2,948, 3,651)2,211, (1,928, 2,410)\n\nSmoking history\n\nNon Smoker86 (66%)29 (49%)\n\nSmoker44 (34%)30 (51%)\n\nn (%)\n\n\n\n\n\n\n6.3.6 Multiline output for all continuous variables.\nIf you wish to print multiline output for all continuous variables, instead of providing “continuous2” argument specified by name of the variable, use continous() in type and statisticarguments.\n\ndf |&gt; \n  select(bwt, low, smoke, lwt) |&gt;\n  tbl_summary(\n    by = low,\n    type = all_continuous() ~ \"continuous2\",\n    statistic = all_continuous()~c(\n      \"{mean}, {sd}\",\n      \"{median}, ({p25}, {p75})\"),\n    label = list(bwt ~ \"Birth Weight\",\n                 smoke ~ \"Smoking history\")) |&gt; as_hux_table()\n\n\n\nCharacteristic\nNormal\nN = 130\nLow Birth Weight\nN = 59\n\n\nBirth Weight\n\nMean, SD3,329, 4782,097, 391\n\nMedian, (Q1, Q3)3,267, (2,948, 3,651)2,211, (1,928, 2,410)\n\nSmoking history\n\nNon Smoker86 (66%)29 (49%)\n\nSmoker44 (34%)30 (51%)\n\nlwt\n\nMean, SD133, 32122, 27\n\nMedian, (Q1, Q3)124, (113, 147)120, (103, 130)\n\nn (%)\n\n\n\n\n\n\n6.3.7 Multiline output for categorical variables.\nThe type argument in tbl_summary function is an optional argument which includes details for the customized outputs according to the type of variables.\n\ndf |&gt; \n  select(bwt, low, smoke) |&gt; \n  tbl_summary(type = all_continuous() ~ \"continuous2\", \n              statistic = list(all_continuous() ~ c(\n                \"{mean} ({sd})\", \n                \"{median} ({p25}, {p75})\"), \n      all_categorical() ~ \"{n} ({p}%)\"),   \n      digits = all_continuous() ~ 1) |&gt; # setting for decimal points\n  as_hux_table()\n\n\n\nCharacteristic\nN = 189\n\n\nbwt\n\nMean (SD)2,944.6 (729.2)\n\nMedian (Q1, Q3)2,977.0 (2,414.0, 3,487.0)\n\nlow\n\nNormal130 (69%)\n\nLow Birth Weight59 (31%)\n\nsmoke\n\nNon Smoker115 (61%)\n\nSmoker74 (39%)\n\nn (%)\n\n\n\n\nTip\nHaving a reproducible code works wonders! Try writing this reproducible code for your own tidy dataset. Voila! You will have publication ready tables.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summary Tables</span>"
    ]
  },
  {
    "objectID": "chapter_7_summary_tables_v2.html#inferential-statistics-and-publication-ready-tables.",
    "href": "chapter_7_summary_tables_v2.html#inferential-statistics-and-publication-ready-tables.",
    "title": "6  Summary Tables",
    "section": "6.4 Inferential statistics and publication ready tables.",
    "text": "6.4 Inferential statistics and publication ready tables.\nCompare the difference in means for a continuous variable in two groups. add_p()function from gtsummarypackage adds p-values to gtsummary table\nIllustrative example: t test\n\ndf |&gt;  \n  select(bwt, smoke) |&gt;  \n  tbl_summary(by = smoke) |&gt;  \n  add_p(bwt ~ \"t.test\") |&gt;  \n  as_hux_table()\n\n\n\nCharacteristic\nNon Smoker\nN = 115\nSmoker\nN = 74\np-value\n\n\nbwt3,100 (2,495, 3,629)2,776 (2,367, 3,260)0.007\n\nMedian (Q1, Q3)\n\nWelch Two Sample t-test\n\n\n\n\nWhat happens if we do not pass any argument to function? Try it!\n\n6.4.1 Statistical tests/ methods available in add_p() function.\nTo find the list of tests available internally within gtsummary, type ?gtsummary::tests in your console. What do you see? There are tbl_summary() variants as well as add_difference variant. Refer to gtsummary vignettes available at https://cran.r-project.org/web/packages/gtsummary/index.html for more details.\n\n\n6.4.2 Automated Inferential statistics with Publication ready tables\nIllustrative example. A researcher is interested to know whether there is a significant difference in mean birth weight as well as proportion of low birth weight babies among mothers with history of smoking during pregnancy as compared to those without history of smoking during pregnancy.\nTo answer the question for this study, the summary statistics should be grouped by smoking history group, which can be done by using the by= argument. To compare two or more groups, include add_p() with the function, which detects variable type and uses an appropriate statistical test.\n\ndf |&gt; \n  select(smoke, bwt, low) |&gt;  \n  tbl_summary(by = smoke) |&gt;  \n  add_p() |&gt;  \n  as_hux_table()\n\n\n\nCharacteristic\nNon Smoker\nN = 115\nSmoker\nN = 74\np-value\n\n\nbwt3,100 (2,495, 3,629)2,776 (2,367, 3,260)0.007\n\nlow0.026\n\nNormal86 (75%)44 (59%)\n\nLow Birth Weight29 (25%)30 (41%)\n\nMedian (Q1, Q3); n (%)\n\nWilcoxon rank sum test; Pearson's Chi-squared test",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summary Tables</span>"
    ]
  },
  {
    "objectID": "chapter_7_summary_tables_v2.html#way-forward",
    "href": "chapter_7_summary_tables_v2.html#way-forward",
    "title": "6  Summary Tables",
    "section": "Way forward",
    "text": "Way forward\nWe have introduced you to one of the most powerful package currently used to develop publication ready tables. It might seem that there is a lot to learn for making publication ready tables using R. Initially, one might feel unnecessary to learn these syntax. However, if you seriously are into creating tables in your professional career, it is recommended and worth investing time to learn these syntax. We are confident your initial effort will save a lot of time subsequently and make you more efficient and accurate in future. Best wishes!",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summary Tables</span>"
    ]
  },
  {
    "objectID": "chapter_8_quarto.html#introduction",
    "href": "chapter_8_quarto.html#introduction",
    "title": "7  Communicating Research with Quarto",
    "section": "7.1 Introduction",
    "text": "7.1 Introduction\nQuarto provides a unified authoring framework for data science, combining your code, its results, and your prose. Quarto documents are fully reproducible and support dozens of output formats, like PDFs, Word files, presentations, and more.\n\n\n\n\n\n\n\nQuarto files are designed to be used in three ways:\n\nFor communicating to decision-makers, who want to focus on the conclusions, not the code behind the analysis.\nFor collaborating with other data scientists (including future you!), who are interested in both your conclusions, and how you reached them (i.e. the code).\nAs an environment in which to do data science, as a modern-day lab notebook where you can capture not only what you did, but also what you were thinking.\n\nQuarto is a command line interface tool, not an R package. This means that help is, by-and-large, not available through ?. Instead, as you work through this chapter, and use Quarto in the future, you should refer to the Quarto documentation (https://quarto.org/).\n\n\n\n\n\n\n\nNote\nQuarto documents are fully reproducible and support dozens of output formats, like PDFs, Word files, slideshows, and more.\nNeed some help?\n\nDownload Quarto: https://quarto.org/docs/get-started/\nQuarto Guide: https://quarto.org/docs/guide/\nMarkdown Reference Sheet: Help &gt; Markdown Quick Reference\n\nYou’ll need the Quarto Command Line Interface but it is automatically done by RStudio for you.\nLet us create one from RStudio now.\nTo create a new Quarto document (.qmd), select File -&gt; New File -&gt; Quarto Document in RStudio, then choose the file type you want to create. For now we will focus on a .html Document, which can be easily converted to other file types later.\nGo ahead and give a title.\nThe newly created .qmd file comes with basic instructions, let us go through it now.\nIt contains three important types of content:\n\nAn (optional) YAML header surrounded by ---\nChunks of R code surrounded by ```\nText mixed with formatting like ## headings and simple text.\n\nYAML stands for yet another markup language or YAML ain’t markup language (a recursive acronym), which emphasizes that YAML is for data, not documents.\nIn any case, it holds the metadata of the document and can be really helpful.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Communicating Research with Quarto</span>"
    ]
  },
  {
    "objectID": "chapter_8_quarto.html#how-does-quarto-work",
    "href": "chapter_8_quarto.html#how-does-quarto-work",
    "title": "7  Communicating Research with Quarto",
    "section": "7.2 How does Quarto work?",
    "text": "7.2 How does Quarto work?\nWhen you render a Quarto document, first knitr executes all of the code chunks and creates a new markdown (.md) document, which includes the code and its output. The markdown file generated is then processed by pandoc, which creates the finished format. The Render button encapsulates these actions and executes them in the right order for you.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Communicating Research with Quarto</span>"
    ]
  },
  {
    "objectID": "chapter_8_quarto.html#some-basics-of-the-markdown-syntax",
    "href": "chapter_8_quarto.html#some-basics-of-the-markdown-syntax",
    "title": "7  Communicating Research with Quarto",
    "section": "7.3 Some Basics of the Markdown syntax",
    "text": "7.3 Some Basics of the Markdown syntax\nLearn more about Markdown from the Guide: https://quarto.org/docs/authoring/markdown-basics.html\nWhen you open an .qmd, you get a notebook interface where code and output are interleaved. You can run each code chunk by clicking the Run icon (it looks like a play button at the top of the chunk), or by pressing Ctrl + Shift + Enter.\nRStudio executes the code and displays the results inline with the code by default. However, you can change it to display in the console instead by clicking on the gear icon and changing the Chunk Output in Console option.\n\n\n\nBasic Markdown Syntax and its output\n\n\n\n\n\n\n\nYou can render the entire document with a single click of a button.\nGo ahead and give it a try. RStudio might prompt you to save the document first, save it in your working directory by giving it a suitable title.\nYou should now see some output like this:\n\n\n\nHTML output of the QMD file",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Communicating Research with Quarto</span>"
    ]
  },
  {
    "objectID": "chapter_8_quarto.html#code-chunks",
    "href": "chapter_8_quarto.html#code-chunks",
    "title": "7  Communicating Research with Quarto",
    "section": "7.4 Code Chunks",
    "text": "7.4 Code Chunks\nThe knitr package extends the basic markdown syntax to include chunks of executable R code.\nWhen you render the report, knitr will run the code and add the results to the output file. You can have the output display just the code, just the results, or both.\nTo embed a chunk of R code into your report, surround the code with two lines that each contain three back ticks. After the first set of backticks, include {r}, which alerts knitr that you have included a chunk of R code. The result will look like this:\n\n\n\nR Code Chunk\n\n\nTo omit the results from your final report (and not run the code) add the argument eval = FALSE inside the brackets and after r. This will place a copy of your code into the report.\n\n\n\nR Code Chunk with `eval` set to FALSE\n\n\nTo omit the code from the final report (while including the results) add the argument echo = FALSE. This is very handy for adding plots to a report, since you usually do not want to see the code that generates the plot.\n\n\n\nR Code Chunk with `echo` set to FALSE\n\n\nRead more about R Code Chunks at https://rmarkdown.rstudio.com/articles_intro.html. You can also change this from the gear icon on the right of the code chunk\n\n7.4.1 Inline R Code\nYou can also evaluate R expressions inline by enclosing the expression within a single back-tick qualified with r.\nknitr will replace the inline code with its result in your final document (inline code is always replaced by its result). The result will appear as if it were part of the original text. For example, the snippet above will appear like this:\n\n\n\nInline R code in RMarkdown documents\n\n\n\n\n\nHTML output of the QMD file\n\n\nNow let us try building our own .qmd document and add our own analysis. Let us use a new dataset for this purpose. So go ahead and delete everything below the YAML header.\n\nThe data we are going to use today is the data of deaths due to COVID-19 in Kerala state. This information is available from the Government of Kerala COVID-19 Dashboard https://dashboard.kerala.gov.in/covid/\n\nLets begin!\n\n\n7.4.2 Workflow with Quarto\n\nCreate a new project and open a new .qmd file in the project.\nLoad Packages\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(rio)\n\n\nLoad the Data\n\n\nmortality_df &lt;- rio::import(\n  here( \"data\", \n    \"GoK Dashboard  Official Kerala COVID-19 Statistics.xlsx\"),\n                       skip = 1)\n\n\nCheck the dimensions of the data\n\n\nmortality_df |&gt; dim()\n\n[1] 21820     9\n\n\n\nYou can alternatively use nrow() and ncol().\n\n\nmortality_df |&gt; nrow()\n\n[1] 21820\n\nmortality_df |&gt; ncol()\n\n[1] 9\n\n\n\nNow try to use them in the R inline code.\n\n\nHint: Use `r ` for inline code chunk like we discussed earlier. Inline R code chunks can be very useful when you are working with data.\n\nText in Quarto:\nThere are 21820 rows in the data \nand 9 columns.\nOutput:\nThere are 21820 rows in the data and 9 columns.\n\nCheck the variable names and clean them\n\nA good practice is to first check all the variable names and clean them using the clean_names() function from the janitor package\n\nmortality_df |&gt; names()\n\n[1] \"SL No.\"                      \"Date Reported\"              \n[3] \"District\"                    \"Name\"                       \n[5] \"Place\"                       \"Age\"                        \n[7] \"Sex\"                         \"Date of death\"              \n[9] \"History(Traveler / contact)\"\n\n\nLook at the difference in the names() of the dataset once it has been cleaned by janitor\n\nmortality_df |&gt; janitor::clean_names() |&gt;  names()\n\n[1] \"sl_no\"                    \"date_reported\"           \n[3] \"district\"                 \"name\"                    \n[5] \"place\"                    \"age\"                     \n[7] \"sex\"                      \"date_of_death\"           \n[9] \"history_traveler_contact\"\n\n\n\nskimr::skim(mortality_df)\n\nThe skim() function shows that date_reported, date_death, and sex are character variables which might not be ideal. Let us transform them into the data types date and factor. also that history_traveler_contact are mostly NA.\nLet us drop the column history_traveler_contact, name and place from our analysis\n\nmortality_df &lt;- mortality_df |&gt; \n  select(-c(history_traveler_contact, name, place))\n\nLets check the class of date_reported.\n\nmortality_df |&gt; pull(date_reported) |&gt; class()\n\n[1] \"character\"\n\n\nLets do some more cleaning of the variables\nWhen working with dates, the lubridate package is ideal.\n\nlibrary(lubridate)\nmortality_df &lt;- mortality_df |&gt; \n  mutate(date_reported = lubridate::dmy(date_reported))\n\nLets check the class of date_reported now\n\nmortality_df |&gt; \n  pull(date_reported) |&gt; \n  class()\n\n[1] \"Date\"\n\n\npull() is an excellent funtion that lets you pull a single varible from a dataset and perform operations. Read more about pull() in the Help menu.\nLet us now look at the sex variable.\n\nmortality_df |&gt; \n  pull(sex) |&gt;\n  unique()\n\n[1] \"Male\"   \"Female\" \"Others\" \"-\"      \"gf\"     \"male\"   NA      \n\n\nAfter some mutate() magic…\n\nmortality_df |&gt; \n  mutate(sex = fct_collapse(sex, Male = \"male\")) |&gt; \n  pull(sex) |&gt; \n  unique()\n\n[1] Male   Female Others -      gf     &lt;NA&gt;  \nLevels: - Female gf Male Others\n\n\nWe can pipe multiple mutate() functions too..\n\nmortality_df &lt;- mortality_df |&gt; \n  mutate(date_of_death = lubridate::dmy(date_of_death)) |&gt; \n  mutate(sex = fct_collapse(sex, Male = \"male\")) |&gt; \n  mutate(sex = factor(sex, levels = c(\"Male\", \"Female\")))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `date_of_death = lubridate::dmy(date_of_death)`.\nCaused by warning:\n!  47 failed to parse.\n\n\nLet us drop_na() for now\n\nmortality_df &lt;- mortality_df |&gt; drop_na()\n\nLet us look at the number of rows now\n\n mortality_df |&gt; nrow()\n\n[1] 21609\n\n\nLet us look at the Districts\n\nmortality_df |&gt; pull(district) |&gt; unique() \n\n [1] \"Thiruvananthapuram\"   \"Kollam\"               \"Pathanamthitta\"      \n [4] \"Kottayam\"             \"Idukki\"               \"Ernakulam\"           \n [7] \"Thrissur\"             \"Palakkad\"             \"Malappuram\"          \n[10] \"Kozhikode\"            \"Wayanad\"              \"Kasaragod\"           \n[13] \"Alappuzha\"            \"Kannur\"               \"Thiruvananthapura m\" \n[16] \"THIRUVANANTHAPURAM\"   \"KOLLAM\"               \"PATHANAMTHITTA\"      \n[19] \"ALAPPUZHA\"            \"KOTTAYAM\"             \"IDUKKI\"              \n[22] \"ERNAKULAM\"            \"THRISSUR\"             \"PALAKKAD\"            \n[25] \"MALAPPURAM\"           \"KOZHIKODE\"            \"WAYANAD\"             \n[28] \"KANNUR\"               \"KASARAGOD\"            \"Kasargod\"            \n[31] \"Thiruvananthapuram?K\" \"Alappuzha?Kannur\"     \"Kollam?Thiruvanantha\"\n[34] \"Malappuaram\"          \"Kozhikode?Thiruvanan\" \"Kozhikode?Ernakulam\" \n[37] \"Eranakulam\"          \n\n\nLet us clean it\n\nmortality_df &lt;- mortality_df |&gt; \n mutate(district = str_to_sentence(district)) |&gt; \n  mutate(district = fct_collapse(district,\n                                 Thiruvananthapuram = c(\n                                   \"Thiruvananthapura m\",\n                                   \"Thiruvananthapuram?K\"))) |&gt; \n  mutate(district = fct_collapse(district, \n                                 Kollam = c(\n                                   \"Kollam?Thiruvanantha\"))) |&gt; \n  mutate(district = fct_collapse(district, \n                                 Ernakulam = c(\n                                   \"Eranakulam\"))) |&gt; \n  mutate(district = fct_collapse(district, \n                                 Kasaragod = c(\n                                   \"Kasargod\"))) |&gt; \n  mutate(district = fct_collapse(district, \n                                 Kozhikode = c(\n                                   \"Kozhikode?Ernakulam\", \n                                   \"Kozhikode?Thiruvanan\"))) |&gt; \n  mutate(district = fct_collapse(district, \n                                 Alappuzha = c(\n                                   \"Alappuzha?Kannur\"))) |&gt; \n  mutate(district = fct_collapse(district, \n                                 Malappuram = c(\n                                   \"Malappuaram\"))) \n\nLet us look at the number of Districts now\n\nmortality_df |&gt; pull(district) |&gt; unique() |&gt; length()\n\n[1] 14\n\n\nLet us now create a new variable called wave. This will tell us if the death has happened in the first wave or second wave of COVID-19.\nFor the workshop’s sake, let us consider April, 2021 as the cut off date for the first wave and second waves of COVID-19 in Kerala.\n\nmortality_df &lt;- mortality_df |&gt; \n   mutate(wave = if_else(date_of_death &lt;= \"2021-04-01\", \n                        \"First Wave\", \n                        \"Second Wave\"))  \n\nLet us create age_group variable\n\nmortality_df &lt;- mortality_df |&gt; mutate(age_group = case_when(\n  age &lt; 60 ~ \"&lt;60 Years\", TRUE ~ \"&gt;60 Years\"))\n\nDistribution of Age and Gender\nLets look at the distribution age and sex among COVID-19 deaths in Kerala\n\nmortality_df |&gt; pull(age) |&gt; summary()\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0      59      68      67      76     121 \n\nmortality_df |&gt; pull(sex) |&gt; factor() |&gt; summary()\n\n  Male Female \n 12777   8832 \n\nmortality_df |&gt; group_by(sex) |&gt; summarize(mean(age), sd(age))\n\n# A tibble: 2 × 3\n  sex    `mean(age)` `sd(age)`\n  &lt;fct&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n1 Male          66.3      13.6\n2 Female        68.0      14.2\n\n\nUsing gtsummary\nlibrary(gtsummary)\nage_sex_table &lt;- mortality_df |&gt;\n  dplyr::select(age, sex) |&gt;  \n  tbl_summary(by = sex) |&gt; \n  add_p()\n\n# using the {gt} package\nas_gt(age_sex_table) |&gt; gt::as_latex()\nUsing the inline R code you can:\n\nThe median (IQR) age (in years) among males and females are \n` r inline_text(age_sex_table, variable = age, \ncolumn = \"stat_1\")` \nand ` r inline_text(age_sex_table, \nvariable = age, column = \"stat_2\")`, respectively.\nOutput:\nThe median (IQR) age (in years) among males and females are 68 (58, 75) and 70 (60, 78) , respectively.\nVisualize using ggplot2\n\nmortality_df |&gt; \n  ggplot(aes(x = sex, y = age)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nDistribution of Age groups and Waves\nage_group_wave_table &lt;- mortality_df |&gt; \n  dplyr::select(age_group, wave) |&gt;  \n  tbl_summary(by = wave) |&gt; \n  add_p()\n\n# using the {gt} package\nas_gt(age_group_wave_table) |&gt; gt::as_latex()\nUsing the inline R code you can:\n\nThe number of deaths in the First wave and Second wave of COVID-19 are  \n\n` r inline_text(age_group_wave_table, variable = age_group, \nlevel = \"&lt;60 Years\", column = \"stat_1\")` and \n\n` r inline_text(age_group_wave_table, variable = age_group, \nlevel = \"&gt;60 Years\", column = \"stat_2\")` , respectively.\nOutput:\nThe number of deaths in the First wave and Second wave of COVID-19 are 1,079 (24%) and 12,467 (73%) , respectively.\nVisualize using ggplot2\n\nmortality_df |&gt; \n  ggplot(aes(x = wave, fill = age_group)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\nLets make more sense from this plot with some mutate() magic again..\n\ndf &lt;- mortality_df |&gt; \n  count(wave, age_group) |&gt; \n  na.omit() |&gt; \n  group_by(wave) |&gt; \n  mutate(prop = (n / sum(n))*100) |&gt; \n  ungroup()\n\n\ndf |&gt; \n  ggplot(aes(x = wave, y = prop,  fill = age_group)) +\n  geom_bar(position = \"dodge\", stat = \"identity\")\n\n\n\n\n\n\n\n\nNow let us knit this!",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Communicating Research with Quarto</span>"
    ]
  },
  {
    "objectID": "chapter_8_quarto.html#conclusion",
    "href": "chapter_8_quarto.html#conclusion",
    "title": "7  Communicating Research with Quarto",
    "section": "7.5 Conclusion",
    "text": "7.5 Conclusion\n\nQuarto is awesome.\n\nThe ratio of markup to content is excellent.\nFor exploratory analyses, blog posts, and interactive documents\nFor journal articles, though knowledge on will be helpful.\n\nThe RStudio team have made the whole process very user friendly.\n\nRStudio provides useful short cut keys for compiling to HTML, and running code chunks.\nThese shortcut keys are presented in a clear way.\nCode completion on R code chunk options is really helpful. See also chunk options documentation on the knitr website.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Communicating Research with Quarto</span>"
    ]
  },
  {
    "objectID": "additional_materials.html#additional-resources",
    "href": "additional_materials.html#additional-resources",
    "title": "Additional Readings",
    "section": "Additional Resources:",
    "text": "Additional Resources:\n\nggplot2 Gallery: https://exts.ggplot2.tidyverse.org/gallery/\nR Graphics Cookbook: https://r-graphics.org/\nTidyverse Course: https://jhudatascience.org/tidyversecourse/get-data.html\nTidyverse Cookbook: https://rstudio-education.github.io/tidyverse-cookbook/import.html\nData Wrangling Cheatsheet: https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf\nR Markdown: The Definitive Guide: https://bookdown.org/yihui/rmarkdown/\nQuarto: https://quarto.org/",
    "crumbs": [
      "Additional Readings"
    ]
  }
]